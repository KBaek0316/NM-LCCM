{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate utility function with higher-order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.distributions.log_normal as log_normal\n",
    "import torch.distributions.uniform as uniform\n",
    "from sklearn import model_selection\n",
    "import torch.distributions.bernoulli as bernoulli                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility\n",
    "$V_j\\\\\n",
    "= b_{0j} + b_1 x_1 + b_2 x_2 + b_3 x_3\\\\\n",
    "= b_{0j} + b_1 x_1 + (a_0 + a_1z_1 + a_2z_2 + a_3z_3 + a_{12}z_1z_2 + a_{13}z_1z_3 + a_{23}z_2z_3) x_2 \\\\\n",
    "= b_{0j} + b_1 x_1 + (a_0 + z^T A_1 + z^T A_2 z) x_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateZ(N):\n",
    "    '''\n",
    "    Generate z=[z0,z1,z2] for N samples (income, full-time, flexible-schedule)\n",
    "    Return: Z (N, 3)\n",
    "    '''\n",
    "    # Define p(z1)\n",
    "    m_fulltime = bernoulli.Bernoulli(0.5) # full time prob = 0.5\n",
    "    \n",
    "    # Define p(z0|z1), p(z2|z1)\n",
    "    m_inc_fulltime = log_normal.LogNormal(torch.Tensor([np.log(0.5)]), 0.25)\n",
    "    m_inc = log_normal.LogNormal(torch.Tensor([np.log(0.25)]), 0.2)\n",
    "    m_flex_fulltime = bernoulli.Bernoulli(0.5)\n",
    "    m_flex = bernoulli.Bernoulli(0.5) \n",
    "    \n",
    "    z = torch.zeros(N,3) # z = (income, job, flex)\n",
    "    \n",
    "    # Draw job \n",
    "    z[:,1] = m_fulltime.sample(sample_shape=(N,)) # N by 1\n",
    "    \n",
    "    # Given z[:,1]=1: draw z[:,0](income), z[:,2] (flex)\n",
    "    ind = z[:,1]==1\n",
    "    ind_sum = ind.sum().item()\n",
    "    z[ind,0] = m_inc_fulltime.sample(sample_shape=(ind_sum,)).flatten()\n",
    "    z[ind,2] = m_flex_fulltime.sample(sample_shape=(ind_sum,)).flatten()\n",
    "    \n",
    "    # Given z[:,1]=0: draw z[:,0](income), z[:,2] (flex)\n",
    "    z[~ind,0] = m_inc.sample(sample_shape=(N-ind_sum,)).flatten()\n",
    "    z[~ind,2] = m_flex.sample(sample_shape=(N-ind_sum,)).flatten()\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_of_x(A0, A1, A2, Z):\n",
    "    '''\n",
    "    Compute value of time for N persons given person characteristics z (N,D)\n",
    "    Input:\n",
    "        A0, A1, A2: 0, 1st and 2nd order interaction coefficients\n",
    "        Z: person input (N,D)\n",
    "    Return:\n",
    "        vox: (N,1)\n",
    "    '''\n",
    "    vox = A0 + torch.matmul(Z,A1) + torch.diag(torch.matmul(torch.matmul(Z,A2), Z.transpose(0,1)))\n",
    "    return vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_one_x(vot, vowt, min_c = 0.2, max_c = 100, min_t = 5, max_t = 100, min_wt = 5, max_wt = 30):\n",
    "    '''\n",
    "    v: value of time ($/min) < 0\n",
    "    \n",
    "    return t0,t1,c0,c1 (time and cost for alternative 0 and 1)\n",
    "    '''\n",
    "    \n",
    "    dist_t = uniform.Uniform(min_t, max_t)\n",
    "    t0 = dist_t.sample().item()\n",
    "    t1 = dist_t.sample().item()\n",
    "    \n",
    "    dist_wt = uniform.Uniform(min_wt, max_wt)\n",
    "    wt0 = dist_wt.sample().item()\n",
    "    wt1 = dist_wt.sample().item()\n",
    "    \n",
    "    while True:\n",
    "        c1_c0 = vot*(t1-t0) + vowt*(wt1-wt0) + torch.randn(1)*2 # add random error up and down the line \n",
    "        \n",
    "        if c1_c0 <= 0 and min_c-c1_c0 <= max_c:\n",
    "            c0 = uniform.Uniform(min_c-c1_c0, max_c).sample().item()\n",
    "            break\n",
    "        elif c1_c0 > 0 and min_c <= max_c-c1_c0:\n",
    "            c0 = uniform.Uniform(min_c, max_c-c1_c0).sample().item()\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    c1 = c0 + c1_c0\n",
    "    c1 = c1.item()\n",
    "    return t0,t1, wt0, wt1, c0,c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateX(vots, vowts):\n",
    "    '''\n",
    "    Generate samples x incl intercept: (N,K+1,J) where J = 2\n",
    "        x[n] = \n",
    "            [0, 1\n",
    "             c0,c1\n",
    "             t0,t1\n",
    "             wt_0, wt_1]\n",
    "        c0, c1: cost in $\n",
    "        t0, t1: time in minutes \n",
    "        wt0, wt1: waiting time in minutes\n",
    "    Return: \n",
    "        X: (N, D, 2)\n",
    "    '''\n",
    "    D = 4 # including ASC\n",
    "    N = vots.size(0)\n",
    "    X = torch.zeros(N,D,2)\n",
    "    n = 0\n",
    "    while (n < N):\n",
    "        t0, t1, wt0, wt1, c0, c1 = generate_one_x(vots[n], vowts[n])\n",
    "        X[n] = torch.Tensor([0, 1, c0, c1, t0, t1, wt0, wt1]).reshape(4,2)\n",
    "        n += 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility(asc0, asc1, X, vots, vowts):\n",
    "    '''\n",
    "    Input:\n",
    "        X: (N,K+1,J)\n",
    "        vots: (N)\n",
    "        vowts: (N)\n",
    "    Returns:\n",
    "        V: (N,J)\n",
    "    '''\n",
    "    N, K_plus_1, J = X.size()\n",
    "    K = K_plus_1-1\n",
    "    V = torch.zeros(N,J)\n",
    "    for n in range(N): \n",
    "        vot_n = vots[n].item()\n",
    "        vowt_n = vowts[n].item()\n",
    "        Bn = torch.Tensor([asc0, asc1, -1, -1, vot_n, vot_n, vowt_n, vowt_n]).reshape(K+1,2) #(K+1,J)\n",
    "        xn = X[n] # (K+1,J)\n",
    "        V[n] = (Bn*xn).sum(dim=0) # 1 by J\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(N):\n",
    "    # generate personal characteristics\n",
    "    Z = generateZ(N) # N, D\n",
    "\n",
    "    # compute vot, vowt\n",
    "    vots = value_of_x(A0_time, A1_time, A2_time, Z) # N\n",
    "    vowts = value_of_x(A0_wait, A1_wait, A2_wait, Z)\n",
    "    \n",
    "    # generate alternative attributes (closer to the decision boundary, which is why we need vots, vowts)\n",
    "    X = generateX(vots, vowts) # (N, K+1, J) = (N, 4, 2)\n",
    "\n",
    "    v = utility(asc0, asc1, X, vots, vowts)\n",
    "\n",
    "    p = torch.softmax(v, dim=1)\n",
    "    m = torch.distributions.categorical.Categorical(probs=p)\n",
    "    y = m.sample()\n",
    "    nll = F.nll_loss(input=torch.log(p),target=y)\n",
    "    acc = (y==p.argmax(1)).sum().float()/N\n",
    "    data = {\"x\": X, \n",
    "            \"z\": Z,\n",
    "            \"y\": y, \n",
    "            \"p\": p, \n",
    "            \"vots\": vots, \n",
    "            \"vowts\": vowts, \n",
    "            \"params\": params,\n",
    "            \"nll\": nll.item(), \n",
    "            \"acc\": acc.item()}\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASC\n",
    "asc0 = 0\n",
    "asc1 = -0.1\n",
    "\n",
    "# 0, 1st and 2nd order effect of z on time and waiting time\n",
    "A0_time = -0.1\n",
    "A1_time = torch.Tensor([-0.5, -0.1, 0.05])\n",
    "A2_time = torch.Tensor(\\\n",
    "                       [[ 0.0000, -0.2000,  0.0500],\n",
    "                        [ 0.0000,  0.0000,  0.1000],\n",
    "                        [ 0.0000,  0.0000,  0.0000]])\n",
    "\n",
    "A0_wait = -0.2\n",
    "A1_wait = torch.Tensor([-0.8, -0.3, 0.1])\n",
    "A2_wait = torch.Tensor(\\\n",
    "                       [[ 0.0000, -0.3000,  0.08],\n",
    "                        [ 0.0000,  0.0000,  0.3000],\n",
    "                        [ 0.0000,  0.0000,  0.0000]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"asc0\": asc0,\n",
    "    \"asc1\": asc1,\n",
    "    \"b_time\": A0_time,\n",
    "    \"b_time_z1\": A1_time[0].item(),\n",
    "    \"b_time_z2\": A1_time[1].item(),\n",
    "    \"b_time_z3\": A1_time[2].item(),\n",
    "    \"b_time_z1z2\": A2_time[0,1].item(),\n",
    "    \"b_time_z1z3\": A2_time[0,2].item(),\n",
    "    \"b_time_z2z3\": A2_time[1,2].item(),\n",
    "    \"b_wait\": A0_wait,\n",
    "    \"b_wait_z1\": A1_wait[0].item(),\n",
    "    \"b_wait_z2\": A1_wait[1].item(),\n",
    "    \"b_wait_z3\": A1_wait[2].item(),\n",
    "    \"b_wait_z1z2\": A2_wait[0,1].item(),\n",
    "    \"b_wait_z1z3\": A2_wait[0,2].item(),\n",
    "    \"b_wait_z2z3\": A2_wait[1,2].item(),\n",
    "    \"A0_time\": A0_time,\n",
    "    \"A1_time\": A1_time,\n",
    "    \"A2_time\": A2_time,\n",
    "    \"A0_wait\": A0_wait,\n",
    "    \"A1_wait\": A1_wait,\n",
    "    \"A2_wait\": A2_wait,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asc0': 0,\n",
       " 'asc1': -0.1,\n",
       " 'b_time': -0.1,\n",
       " 'b_time_z1': -0.5,\n",
       " 'b_time_z2': -0.10000000149011612,\n",
       " 'b_time_z3': 0.05000000074505806,\n",
       " 'b_time_z1z2': -0.20000000298023224,\n",
       " 'b_time_z1z3': 0.05000000074505806,\n",
       " 'b_time_z2z3': 0.10000000149011612,\n",
       " 'b_wait': -0.2,\n",
       " 'b_wait_z1': -0.800000011920929,\n",
       " 'b_wait_z2': -0.30000001192092896,\n",
       " 'b_wait_z3': 0.10000000149011612,\n",
       " 'b_wait_z1z2': -0.30000001192092896,\n",
       " 'b_wait_z1z3': 0.07999999821186066,\n",
       " 'b_wait_z2z3': 0.30000001192092896,\n",
       " 'A0_time': -0.1,\n",
       " 'A1_time': tensor([-0.5000, -0.1000,  0.0500]),\n",
       " 'A2_time': tensor([[ 0.0000, -0.2000,  0.0500],\n",
       "         [ 0.0000,  0.0000,  0.1000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]),\n",
       " 'A0_wait': -0.2,\n",
       " 'A1_wait': tensor([-0.8000, -0.3000,  0.1000]),\n",
       " 'A2_wait': tensor([[ 0.0000, -0.3000,  0.0800],\n",
       "         [ 0.0000,  0.0000,  0.3000],\n",
       "         [ 0.0000,  0.0000,  0.0000]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(params, open(\"toy_data/params.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data （training 10K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "N_train, N_dev, N_test = 10000, 2000, 2000\n",
    "\n",
    "data_train = generateData(N_train)\n",
    "data_dev = generateData(N_dev)\n",
    "data_test = generateData(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46460282802581787\n",
      "0.44120335578918457\n",
      "0.4465537369251251\n"
     ]
    }
   ],
   "source": [
    "print (data_train['nll'])\n",
    "print (data_dev['nll'])\n",
    "print (data_test['nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x', 'z', 'y', 'p', 'vots', 'vowts', 'params', 'nll', 'acc'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"train\": data_train, 'dev': data_dev, \"test\": data_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_train, open(\"toy_data/train_10k.pkl\",\"wb\"))\n",
    "pickle.dump(data_dev, open(\"toy_data/dev_10k.pkl\",\"wb\"))\n",
    "pickle.dump(data_test, open(\"toy_data/test_10k.pkl\",\"wb\"))\n",
    "pickle.dump(data, open(\"toy_data/data_10k.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate data（training 100K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(7)\n",
    "N_train, N_dev, N_test = 100000, 2000, 2000\n",
    "\n",
    "data_train = generateData(N_train)\n",
    "data_dev = generateData(N_dev)\n",
    "data_test = generateData(N_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4619007706642151\n",
      "0.44855937361717224\n",
      "0.4844731390476227\n"
     ]
    }
   ],
   "source": [
    "print (data_train['nll'])\n",
    "print (data_dev['nll'])\n",
    "print (data_test['nll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"train\": data_train, 'dev': data_dev, \"test\": data_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(data_train, open(\"toy_data/train_100k.pkl\",\"wb\"))\n",
    "pickle.dump(data_dev, open(\"toy_data/dev_100k.pkl\",\"wb\"))\n",
    "pickle.dump(data_test, open(\"toy_data/test_100k.pkl\",\"wb\"))\n",
    "pickle.dump(data, open(\"toy_data/data_100k.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000, 4, 2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['x'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = data_train[\"z\"].numpy()\n",
    "x = data_train[\"x\"]\n",
    "y = data_train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe z\n",
    "print (\"==Training Data (z)==\")\n",
    "\n",
    "# full-time, flexibile\n",
    "print (\"full-time, flexible\", ((z[:,1]==1) & (z[:,2]==1)).sum())\n",
    "print (\"full-time, not flexible\",((z[:,1]==1) & (z[:,2]==0)).sum())\n",
    "print( \"not full-time, flexible\", ((z[:,1]==0) & (z[:,2]==1)).sum())\n",
    "print (\"not full-time, not flexible\",((z[:,1]==0) & (z[:,2]==0)).sum())\n",
    "\n",
    "# income\n",
    "plt.hist(z[:,0]*60)\n",
    "plt.xlabel(\"Income ($ per hour)\")\n",
    "plt.savefig(\"toy_data/hist_income.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Describe z\n",
    "print (\"==Training Data (y)==\")\n",
    "\n",
    "# income \n",
    "plt.hist(z[:,0]*60)\n",
    "plt.xlabel(\"Income ($ per hour)\")\n",
    "plt.savefig(\"toy_data/hist_income.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost\n",
    "plt.hist(x[:,1,:].numpy())\n",
    "plt.xlabel(\"Cost ($)\")\n",
    "print (\"cost (min, max)=\", x[:,1,:].min(), x[:,1,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = sorted(x[:,1,:].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time\n",
    "plt.hist(x[:,2,:].numpy())\n",
    "plt.xlabel(\"Time (min)\")\n",
    "print (\"time (min, max)=\", x[:,2,:].min(), x[:,2,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting time\n",
    "plt.hist(x[:,2,:].numpy())\n",
    "plt.xlabel(\"Waiting Time (min)\")\n",
    "print (\"time (min, max)=\", x[:,3,:].min(), x[:,3,:].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot true VOT\n",
    "inc = torch.arange(0.0, 1.0, 0.02).reshape(-1,1)\n",
    "x_inc = (inc*60).tolist()\n",
    "n = len(inc)\n",
    "fulltime = torch.ones(n,1)\n",
    "nofulltime = torch.zeros(n,1)\n",
    "flex = torch.ones(n,1)\n",
    "noflex = torch.zeros(n,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_full_flex = torch.cat((inc,fulltime,flex),dim=1)\n",
    "z_full_noflex = torch.cat((inc,fulltime,noflex),dim=1)\n",
    "z_nofull_flex = torch.cat((inc,nofulltime,flex),dim=1)\n",
    "z_nofull_noflex = torch.cat((inc,nofulltime,noflex),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vots = \\\n",
    "[value_of_x(A0_time, A1_time, A2_time, z_full_flex),\n",
    "value_of_x(A0_time, A1_time, A2_time, z_full_noflex),\n",
    "value_of_x(A0_time, A1_time, A2_time, z_nofull_flex),\n",
    "value_of_x(A0_time, A1_time, A2_time, z_nofull_noflex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_vowts = \\\n",
    "[value_of_x(A0_wait, A1_wait, A2_wait, z_full_flex),\n",
    "value_of_x(A0_wait, A1_wait, A2_wait, z_full_noflex),\n",
    "value_of_x(A0_wait, A1_wait, A2_wait, z_nofull_flex),\n",
    "value_of_x(A0_wait, A1_wait, A2_wait, z_nofull_noflex)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_true = plt.figure()\n",
    "for e in true_vots:\n",
    "    plt.plot(x_inc,(-e*60).tolist())\n",
    "plt.legend(['full-time, flex', 'full-time, not flex', 'not full-time, flex', 'not full-time, not flex'])\n",
    "plt.xlabel(\"income ($ per hour)\")\n",
    "plt.ylabel(\"value of time ($ per hour)\")\n",
    "plt.ylim(0, 60)\n",
    "plt.title(\"Value of Time vs. Hourly Income (True)\")\n",
    "plt.savefig(\"toy_data/vot_true.png\", dpi=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_true = plt.figure()\n",
    "for e in true_vowts:\n",
    "    plt.plot(x_inc,(-e*60).tolist())\n",
    "plt.legend(['full-time, flex', 'full-time, not flex', 'not full-time, flex', 'not full-time, not flex'])\n",
    "plt.xlabel(\"income ($ per hour)\")\n",
    "plt.ylabel(\"value of waiting time ($ per hour)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.title(\"Value of Waiting Time vs. Hourly Income (True)\")\n",
    "plt.savefig(\"toy_data/vowt_true.png\", dpi=250)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
